퍼셉트론 :
입력값과 활성화 함수를 사용해서 출력 값을 다음으로 넘기기는 가장 작은  인공 신경망 단위
N개의 이진수가 하나의 뉴런을 통과해서 가중합이 0보다 크면 활성화되는 가장 간단한 신경망 구조
초평면(hyperplane)으로 구분되는 두개의 공간을 분리하는 역할 - AND게이트, OR게이트를 만들 수 있다
XOR게이트를 퍼셉트론으로 구현하기 위해서는 좌표 평면 자체에 변화를 주는 은닉층을 만들어서 공간을 왜곡하면 두 영역으로 분류 가능
XOR게이트를 퍼셉트론으로 구현하기 위해서는 두개의 퍼셉트론을 한번에 계산할 수 있어야 합니다.

퍼셉트론 신경망 수행 흐름 :
환경변수 지정(출력뉴런수, 입력데이터에 적용할 가중치, 가중합에 적용될 바이어스, 활성화함수, 은닉층 수) ->신경망 실행-> 결과를 실제값과 비교 -> 계산된 오차를 출력층과 은닉층의 가중치를 수정 (오차 역전파)  -> 신경망 실행 ->....-> 결과 출력 (분류, 예측)

은닉층으로의 출력에 사용될 활성화 함수 : 기울기 소실문제를 해결해주는 ReLu
출력층에 사용될 활성화 함수 : sigmoid(이항 분류), softmax(다항 분류), 선형회귀(연속형 변수의 값 예측)[얘는 출력층의 활성화 함수로 따로 지정하지 않는다.)

모든 데이터에 대해서 미분값 계산은 수행 속도 저하가 발생 -> 랜덤하게 추출한 일부 데이터를 사용해서 더 빠르게 수행(확률적 경사 하강법, SGD 함수)

모멘텀 : 관성을 이용하여, 방향을 고려해서 진동폭을 줄이기 위해서 사용

알엠에스프롭(RMSprop) - 아다그라드 보폭 민감도를 보완한 방법
아담(Adaram) - 모멘텀 + 알엠에스 프롭(RMS PROP)
Sequential() - Keras에서 제공하는 모델구조를 구성할 수 있는 객체

add(Dense())
add(Activate(출력뉴런수,input_index ,input_dim= ,init = , activation=)) : 입력층 -> 은닉층 구조(layer)
add(Dense(출력뉴런수, activation=))
add(Dense(1, activation =)) 은닉층 -> 출력층 구조(layer)

1 epoch - 학습 프로세스에서 모든 샘플에 대해서, 한번 실행되는것
다중 분류시에 class가 object 타입으로(BMI문제), thin, normal, fat -> 정수변환(LabelEncoder) -> one-hot-encoding 변환 (keras.utils.np_utils.to_categorical)

Sequential()을 이용해서 신경망 layer 구성 후
compile(loss = 오차함수, optimizer = 성능최적화 함수, metrics = 정확도, 재현율 등 측정 함수)
fit(독립변수에 해당하는 데이터 객체, 종속변수에 해당하는 데이터 객체, epochs =, batch_size =)학습 



[오차함수]
mean_squared_error : 평균 제곱 오차
mean_absolute_error : 평균 절대 오차
mean_absolute_percentage_error:평균 절대 백분율 오차
mean_squared_logartithmetic_error:평균제곱 로그 오차

분류문제에서는 정확률과 재현률 측정 - categorical_crossentropy(범주형 교차 엔트로피), binary_crossentropy(이항 교차 엔트로피)

과적합을 줄이기 위한 방법
학습데이터와 테스트 데이터 분리
train_testsplit(독립변수데이터 객체, 종속변수 데이터 객체, test =, random_state = ) 학습데이터와 테스트 데이터 분리

학습 결과 모델을 저장 : save()
학습결과 모델을 메모리로 로딩 : load_model()

K겹 교차 검증 - 학습데이터(테스트 데이터)가 적을 경우, 데이터셋을 여러개로 나누어 하나씩 테스트 셋으로 사용하면(전체 데이터를 테스트 셋으로 사용할 수 있다.)
sklearn.model_selection.StratifiedKFold(n_splits = , shuffle =, random_state = )

keras.callbacks.ModelCheckpoint(filepath =, monitor =, verbose =, save_best_only) - Epoch마다 모델의 정확도를 기록 저장

Epoch마다 생성된 모델 객체에는 배열로 학습 정확도acc, 검증 정확도val_acc, 학습 손실값loss, 검증 손실값val_loss

과적합이 발생하기 시작됨을 생성된 모델 객체의 테스트 오차 속성 val_loss값이 감소하다가 다시 증가하기 시작하면....

과적합이 발생하기 시작됨을 생성된 모델 객체의 테스트의 오차 속성 val_loss 값이 감소하다가 다시 증가하기 시작하면....
과적합이 발생하면, 신경망 학습 수행 중단 : EarlyStopping(monitor='val_loss', 'patience =)

Dense Layer 마다 출력 뉴런수 설정(제약이 없다.)
Dense Layer 구조, 개수 등의 설정에 따라 모델의 성능이 달라지므로, Dense 생성시에 변경가능한 옵션들, Layer 수등을 조정해서 튜닝합니다.

fit()의 기본 로그는 손실값과 정확도가 표시됩니다.
이진분류는 정확도를 통해서 제대로 학습이 되고, 있는지 확인 가능
다중분류는 정확도 재현율 등.... 학습이 되고 있는지 확인 가능
metrics는 평가 기준

evaluate() - 모델을 평가, 손실값 및 metrics값 등을 반환
